{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a0e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad888cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def lat_to_scale(lat):\n",
    "    \"\"\"Compute Mercator scale from latitude.\"\"\"\n",
    "    return np.cos(lat * np.pi / 180.0)\n",
    "\n",
    "def latlon_to_mercator(lat, lon, scale):\n",
    "    \"\"\"Convert lat/lon to mercator coordinates.\"\"\"\n",
    "    er = 6378137.0  # earth radius (m)\n",
    "    mx = scale * lon * np.pi * er / 180.0\n",
    "    my = scale * er * np.log(np.tan((90.0 + lat) * np.pi / 360.0))\n",
    "    return mx, my\n",
    "\n",
    "def convert_oxts_to_pose(oxts):\n",
    "    \"\"\"\n",
    "    Converts a list of oxts measurements into metric poses.\n",
    "    Each element of `oxts` is expected to be a numpy array or list:\n",
    "    [lat, lon, alt, roll, pitch, yaw]\n",
    "    \"\"\"\n",
    "    if len(oxts) == 0:\n",
    "        return []\n",
    "\n",
    "    # Compute scale from first lat value\n",
    "    scale = lat_to_scale(oxts[0][0])\n",
    "\n",
    "    poses = []\n",
    "    Tr_0_inv = None\n",
    "\n",
    "    for packet in oxts:\n",
    "        if packet is None or len(packet) == 0:\n",
    "            poses.append(None)\n",
    "            continue\n",
    "\n",
    "        lat, lon, alt, roll, pitch, yaw = packet[:6]\n",
    "\n",
    "        # translation vector\n",
    "        tx, ty = latlon_to_mercator(lat, lon, scale)\n",
    "        tz = alt\n",
    "        t = np.array([[tx], [ty], [tz]])\n",
    "\n",
    "        # rotation matrix\n",
    "        Rx = np.array([\n",
    "            [1, 0, 0],\n",
    "            [0, np.cos(roll), -np.sin(roll)],\n",
    "            [0, np.sin(roll),  np.cos(roll)]\n",
    "        ])\n",
    "        Ry = np.array([\n",
    "            [np.cos(pitch), 0, np.sin(pitch)],\n",
    "            [0, 1, 0],\n",
    "            [-np.sin(pitch), 0, np.cos(pitch)]\n",
    "        ])\n",
    "        Rz = np.array([\n",
    "            [np.cos(yaw), -np.sin(yaw), 0],\n",
    "            [np.sin(yaw),  np.cos(yaw), 0],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        R = Rz @ Ry @ Rx\n",
    "\n",
    "        # homogeneous transform\n",
    "        Tr = np.vstack((np.hstack((R, t)), [0, 0, 0, 1]))\n",
    "\n",
    "        # normalize translation and rotation (start at 0/0/0)\n",
    "        if Tr_0_inv is None:\n",
    "            Tr_0_inv = np.linalg.inv(Tr)\n",
    "\n",
    "        pose = Tr_0_inv @ Tr\n",
    "        poses.append(pose)\n",
    "\n",
    "    return poses\n",
    "\n",
    "\n",
    "def load_oxts_lite_data(base_dir, frames=None):\n",
    "    \"\"\"\n",
    "    Reads KITTI GPS/IMU (OXTSlite) data from files.\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): Path to sequence directory (should contain \"oxts/data/\").\n",
    "        frames (list[int] or None): If None, load all frames. Otherwise load only the given frames.\n",
    "    \n",
    "    Returns:\n",
    "        list of numpy arrays: Each entry is one OXTS packet (30 floats).\n",
    "                             Missing files â†’ None.\n",
    "    \"\"\"\n",
    "    data_dir = os.path.join(base_dir, \"oxts\", \"data\")\n",
    "\n",
    "    oxts = []\n",
    "\n",
    "    if frames is None:\n",
    "        # load all files in directory, sorted by index\n",
    "        all_files = sorted(os.listdir(data_dir))\n",
    "        for fname in all_files:\n",
    "            if fname.endswith(\".txt\"):\n",
    "                fpath = os.path.join(data_dir, fname)\n",
    "                try:\n",
    "                    arr = np.loadtxt(fpath)\n",
    "                    oxts.append(arr)\n",
    "                except Exception:\n",
    "                    oxts.append(None)\n",
    "    else:\n",
    "        # load only requested frames\n",
    "        for idx in frames:\n",
    "            fname = f\"{idx:010d}.txt\"   # MATLAB used (frames(i)-1), but KITTI indexes from 0 already\n",
    "            fpath = os.path.join(data_dir, fname)\n",
    "            try:\n",
    "                arr = np.loadtxt(fpath)\n",
    "                oxts.append(arr)\n",
    "            except Exception:\n",
    "                oxts.append(None)\n",
    "\n",
    "    return oxts\n",
    "\n",
    "def load_images(base_dir,frames):\n",
    "    data_dir_left = os.path.join(base_dir,\"image_02\",\"data\")\n",
    "    data_dir_right = os.path.join(base_dir,\"image_03\",\"data\")\n",
    "    \n",
    "    left_images = []\n",
    "    right_images = []\n",
    "    \n",
    "    for idx in frames:\n",
    "        fname = f\"{idx:010d}.png\"   # MATLAB used (frames(i)-1), but KITTI indexes from 0 already\n",
    "        fpath_left = os.path.join(data_dir_left, fname)\n",
    "        fpath_right = os.path.join(data_dir_right, fname)\n",
    "        print(fpath_left)\n",
    "        try:\n",
    "            left = cv2.imread(fpath_left)\n",
    "            right = cv2.imread(fpath_right)\n",
    "            left_images.append(left)\n",
    "            right_images.append(right)\n",
    "        except Exception:\n",
    "            left_images.append(None)\n",
    "            right_images.append(None)\n",
    "    return left_images,right_images        \n",
    "\n",
    "def read_depth(base_dir,frames):\n",
    "    \"\"\"\n",
    "    Read a KITTI .bin Velodyne file.\n",
    "    Each point has (x, y, z, reflectance).\n",
    "    \n",
    "    Args:\n",
    "        bin_path (str): Path to the .bin file.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray of shape (N, 4) with columns [x, y, z, reflectance].\n",
    "    \"\"\"\n",
    "    # Each point is 4 floats (16 bytes)\n",
    "    depth_dir = os.path.join(base_dir,\"velodyne_points\",\"data\")\n",
    "    pcds = []\n",
    "    for idx in frames:\n",
    "        fname = f\"{idx:010d}.bin\"   # MATLAB used (frames(i)-1), but KITTI indexes from 0 already\n",
    "        bin_path = os.path.join(depth_dir,fname)\n",
    "        point_cloud = np.fromfile(bin_path, dtype=np.float32)\n",
    "        point_cloud =  point_cloud.reshape(-1,4)\n",
    "        pcds.append(point_cloud[:,:3])\n",
    "    return pcds\n",
    "\n",
    "def write_kitti_bin(bin_path, points):\n",
    "    \"\"\"\n",
    "    Write KITTI format .bin Velodyne file.\n",
    "    \n",
    "    Args:\n",
    "        bin_path (str): Path to save .bin file.\n",
    "        points (np.ndarray): Array of shape (N, 4) with [x, y, z, reflectance].\n",
    "    \"\"\"\n",
    "    points.astype(np.float32).tofile(bin_path)\n",
    "\n",
    "def convert_velo_2_cam(calib_file,points):\n",
    "        R, T = None, None\n",
    "        R_rect = [\n",
    "    9.998817e-01,  1.511453e-02, -2.841595e-03, 0,\n",
    "   -1.511724e-02,  9.998853e-01, -9.338510e-04, 0,\n",
    "    2.827154e-03,  9.766976e-04,  9.999955e-01, 0,\n",
    "    0,0,0,1\n",
    "]\n",
    "        points = np.hstack([points,np.ones((points.shape[0],1))])\n",
    "        R_rect = np.array(R_rect).reshape(4, 4)\n",
    "        with open(calib_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"R:\"):\n",
    "                    values = [float(x) for x in line.split()[1:]]\n",
    "                    R = np.array(values).reshape(3, 3)\n",
    "                elif line.startswith(\"T:\"):\n",
    "                    values = [float(x) for x in line.split()[1:]]\n",
    "                    T = np.array(values).reshape(3, 1)      \n",
    "        if R is None or T is None:\n",
    "            raise ValueError(\"File does not contain both R and T lines\")        \n",
    "        # Build 4x4 transformation\n",
    "        Tr = np.eye(4)\n",
    "        Tr[:3, :3] = R\n",
    "        Tr[:3, 3] = T.flatten()     \n",
    "        T = R_rect@Tr\n",
    "        print(T.shape)\n",
    "        points_cam = ((T@points.T).T)[:,:3]\n",
    "        return points_cam,T \n",
    "\n",
    "def convert_imu_2_velo(calib_file):\n",
    "        R, T = None, None\n",
    "\n",
    "        with open(calib_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"R:\"):\n",
    "                    values = [float(x) for x in line.split()[1:]]\n",
    "                    R = np.array(values).reshape(3, 3)\n",
    "                elif line.startswith(\"T:\"):\n",
    "                    values = [float(x) for x in line.split()[1:]]\n",
    "                    T = np.array(values).reshape(3, 1)      \n",
    "        if R is None or T is None:\n",
    "            raise ValueError(\"File does not contain both R and T lines\")        \n",
    "        # Build 4x4 transformation\n",
    "        Tr = np.eye(4)\n",
    "        Tr[:3, :3] = R\n",
    "        Tr[:3, 3] = T.flatten()     \n",
    "\n",
    "        return Tr \n",
    "\n",
    "def show_image(img,winname=\"default\"):\n",
    "    cv2.imshow(winname,img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e8bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_velo2cam_matrix(calib_file):\n",
    "    \"\"\"\n",
    "    Reads a KITTI Velodyne-to-camera calibration file and returns the 4x4 transformation matrix.\n",
    "\n",
    "    Args:\n",
    "        calib_file (str): Path to calib_velo_to_cam.txt\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 4x4 transformation matrix\n",
    "    \"\"\"\n",
    "    R, T = None, None\n",
    "\n",
    "    # Rectification matrix (KITTI default)\n",
    "    R_rect = [\n",
    "        9.998817e-01,  1.511453e-02, -2.841595e-03, 0,\n",
    "       -1.511724e-02,  9.998853e-01, -9.338510e-04, 0,\n",
    "        2.827154e-03,  9.766976e-04,  9.999955e-01, 0,\n",
    "        0,0,0,1\n",
    "    ]\n",
    "    R_rect = np.array(R_rect).reshape(4, 4)\n",
    "\n",
    "    # Read R and T from calib file\n",
    "    with open(calib_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"R:\"):\n",
    "                values = [float(x) for x in line.split()[1:]]\n",
    "                R = np.array(values).reshape(3, 3)\n",
    "            elif line.startswith(\"T:\"):\n",
    "                values = [float(x) for x in line.split()[1:]]\n",
    "                T = np.array(values).reshape(3, 1)\n",
    "\n",
    "    if R is None or T is None:\n",
    "        raise ValueError(\"File does not contain both R and T lines\")\n",
    "\n",
    "    # Build 4x4 transformation matrix\n",
    "    Tr = np.eye(4)\n",
    "    Tr[:3, :3] = R\n",
    "    Tr[:3, 3] = T.flatten()\n",
    "\n",
    "    # Multiply by rectification matrix\n",
    "    T_velo2cam = R_rect @ Tr\n",
    "\n",
    "    return T_velo2cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b60155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VELO2CAM_FILE = \"./data/2011-09-26-KITTI/2011_09_26/calib_velo_to_cam.txt\"\n",
    "BASE_DIR = \"./data/2011-09-26-KITTI/2011_09_26_drive_0093_sync\"\n",
    "FRAMES = [63,64]\n",
    "CALIB_VELO2CAM = \"./data/2011-09-26-KITTI/2011_09_26/calib_velo_to_cam.txt\"\n",
    "CALIB_IMU2VELO = \"./data/2011-09-26-KITTI/2011_09_26/calib_imu_to_velo.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9840c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 433 poses to 10.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# -------------------------------# Set directories# -------------------------------\n",
    "OXTSDIR = os.path.join(BASE_DIR, \"oxts\", \"data\")\n",
    "OUTPUT_FILE = \"10.txt\"\n",
    "\n",
    "all_files = sorted([f for f in os.listdir(OXTSDIR) if f.endswith(\".txt\")])\n",
    "frame_indices = [int(f.split(\".\")[0]) for f in all_files]\n",
    "\n",
    "\n",
    "oxts_all = load_oxts_lite_data(BASE_DIR, frames=frame_indices)\n",
    "\n",
    "\n",
    "poses_all = convert_oxts_to_pose(oxts_all)\n",
    "\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    for pose in poses_all:\n",
    "        if pose is None:\n",
    "            f.write(\"None\\n\")\n",
    "        else:\n",
    "            pose_flat = pose.flatten()\n",
    "            line = \" \".join([f\"{x:.6f}\" for x in pose_flat])\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(poses_all)} poses to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c2be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 433 poses to 10_cam.txt (camera frame)\n"
     ]
    }
   ],
   "source": [
    "# Get T_velo2cam once\n",
    "T_velo2cam = get_velo2cam_matrix(VELO2CAM_FILE)\n",
    "\n",
    "OUTPUT_FILE_CAM = \"10_cam.txt\"\n",
    "\n",
    "with open(OUTPUT_FILE_CAM, \"w\") as f:\n",
    "    for pose in poses_all:\n",
    "        if pose is None:\n",
    "            f.write(\"None\\n\")\n",
    "        else:\n",
    "            # Transform the pose to camera frame\n",
    "            pose_cam = T_velo2cam @ pose\n",
    "            # Flatten and save\n",
    "            pose_flat = pose_cam.flatten()\n",
    "            line = \" \".join([f\"{x:.6f}\" for x in pose_flat])\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(poses_all)} poses to {OUTPUT_FILE_CAM} (camera frame)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "13c3a15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aadi_iiith/Downloads/2011_09_26_drive_0002_sync/2011_09_26/2011_09_26_drive_0002_sync/image_02/data/0000000063.png\n",
      "/home/aadi_iiith/Downloads/2011_09_26_drive_0002_sync/2011_09_26/2011_09_26_drive_0002_sync/image_02/data/0000000064.png\n"
     ]
    }
   ],
   "source": [
    "left_images,right_images = load_images(BASE_DIR,FRAMES)\n",
    "velo_depth = read_depth(BASE_DIR,FRAMES)\n",
    "oxts = load_oxts_lite_data(BASE_DIR,FRAMES)\n",
    "poses = convert_oxts_to_pose(oxts) \n",
    "pcd0 = o3d.geometry.PointCloud()\n",
    "pcd0.points = o3d.utility.Vector3dVector(velo_depth[0])\n",
    "\n",
    "pcd1 = o3d.geometry.PointCloud()\n",
    "pcd1.points = o3d.utility.Vector3dVector(velo_depth[1])\n",
    "TI2V = convert_imu_2_velo(CALIB_IMU2VELO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6cd92ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd0,pcd1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2a32e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd0,pcd1.transform(poses[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7aa77761",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd0.transform(T),pcd1.transform(T)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3496ee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.19723460e+02 -1.14769478e+01  6.11599207e+02]\n",
      " [ 1.04145690e+01  7.21296766e+02  1.73558727e+02]\n",
      " [-2.84160779e-03 -9.33855202e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "R = np.array([\n",
    "    [9.998817e-01,  1.511453e-02, -2.841595e-03],\n",
    "    [-1.511724e-02, 9.998853e-01, -9.338510e-04],\n",
    "    [2.827154e-03,  9.766976e-04,  9.999955e-01]\n",
    "])\n",
    "\n",
    "P = np.array([\n",
    "    [7.215377e+02, 0.000000e+00, 6.095593e+02, 4.485728e+01],\n",
    "    [0.000000e+00, 7.215377e+02, 1.728540e+02, 2.163791e-01],\n",
    "    [0.000000e+00, 0.000000e+00, 1.000000e+00, 2.745884e-03]\n",
    "])\n",
    "\n",
    "def recover_K_from_P_and_R(P, R):\n",
    "    \"\"\"\n",
    "    Given P (3x4) and R (3x3), return intrinsic K (3x3).\n",
    "    Handles the common cases where R is a rotation (uses R.T),\n",
    "    otherwise uses np.linalg.inv(R).\n",
    "    Ensures positive diagonal in K and normalizes K[2,2]=1.\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    R = np.asarray(R, dtype=float)\n",
    "    if P.shape != (3, 4):\n",
    "        raise ValueError(\"P must be shape (3,4)\")\n",
    "    if R.shape != (3, 3):\n",
    "        raise ValueError(\"R must be shape (3,3)\")\n",
    "\n",
    "    M = P[:, :3]  # left 3x3 block\n",
    "\n",
    "    # Use R.T if R is (almost) orthonormal; otherwise use inverse\n",
    "    if np.allclose(R @ R.T, np.eye(3), atol=1e-6):\n",
    "        Rinv = R.T\n",
    "    else:\n",
    "        Rinv = np.linalg.inv(R)\n",
    "\n",
    "    K_raw = M @ Rinv\n",
    "\n",
    "    # Fix sign on diagonal: enforce positive diagonal entries\n",
    "    diag_sign = np.sign(np.diag(K_raw))\n",
    "    # replace zeros with +1 (in case any diag element is exactly 0)\n",
    "    diag_sign[diag_sign == 0] = 1.0\n",
    "    S = np.diag(diag_sign)\n",
    "    K_signed = K_raw @ S\n",
    "    # Optionally adjust R as well: R_corrected = S @ R   (not returned here)\n",
    "\n",
    "    # Normalize so that K[2,2] == 1\n",
    "    K = K_signed / K_signed[2, 2]\n",
    "\n",
    "    return K\n",
    "\n",
    "# Example usage:\n",
    "# P = np.array([...]).reshape(3,4)\n",
    "# R = np.array([...]).reshape(3,3)\n",
    "K = recover_K_from_P_and_R(P, R)\n",
    "print(K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "48b70cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 1248)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48519/465659880.py:12: RuntimeWarning: divide by zero encountered in divide\n",
      "  depth0  = (388.68)/disp0\n",
      "/tmp/ipykernel_48519/465659880.py:13: RuntimeWarning: divide by zero encountered in divide\n",
      "  depth1  = (388.68)/disp1\n"
     ]
    }
   ],
   "source": [
    "disp0 = cv2.imread(\"depth_raw_0.png\",cv2.IMREAD_GRAYSCALE)\n",
    "print(disp0.shape)\n",
    "disp0 = cv2.resize(disp0,(1242,375))\n",
    "disp1 = cv2.imread(\"depth_raw_1.png\",cv2.IMREAD_GRAYSCALE)\n",
    "disp1 = cv2.resize(disp1,(1242,375))\n",
    "disp1 = disp1.astype(np.float32)\n",
    "disp1 = disp1*0.75\n",
    "disp1 [:disp1.shape[0]//2,:] = 0\n",
    "disp0 = disp0.astype(np.float32)\n",
    "disp0 = disp0*0.75\n",
    "disp0 [:disp0.shape[0]//2,:] = 0\n",
    "depth0  = (388.68)/disp0   \n",
    "depth1  = (388.68)/disp1\n",
    "   \n",
    "rgbd_ref = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    o3d.geometry.Image(left_images[0]),\n",
    "    o3d.geometry.Image(depth0.astype(np.float32)),\n",
    "    depth_scale=1, depth_trunc=3000.0, convert_rgb_to_intensity=False)\n",
    "intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "intrinsic.intrinsic_matrix = K\n",
    "pcd_0 = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_ref, intrinsic)\n",
    "\n",
    "rgbd_ref = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    o3d.geometry.Image(left_images[1]),\n",
    "    o3d.geometry.Image(depth1.astype(np.float32)),\n",
    "    depth_scale=1, depth_trunc=3000.0, convert_rgb_to_intensity=False)\n",
    "intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "intrinsic.intrinsic_matrix = K\n",
    "pcd_1 = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_ref, intrinsic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f699fd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "cam_points,T = convert_velo_2_cam(CALIB_VELO2CAM,velo_depth[0])\n",
    "pcdcam0 = o3d.geometry.PointCloud()\n",
    "pcdcam0.points = o3d.utility.Vector3dVector(cam_points)\n",
    "cam_points1,T = convert_velo_2_cam(CALIB_VELO2CAM,velo_depth[1])\n",
    "pcdcam1 = o3d.geometry.PointCloud()\n",
    "pcdcam1.points = o3d.utility.Vector3dVector(cam_points1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9380be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses[1] = T@poses[1]@np.linalg.inv(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c69168dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original translation: [0.04137541 0.04645703 1.18382996]\n",
      "Noise vector (|noise|=0.500): [ 0.41068614  0.26318798 -0.10985892]\n",
      "Noisy translation:    [0.45206155 0.30964501 1.07397104]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pose_noisy = poses[1].copy()\n",
    "\n",
    "# Generate a random Gaussian 3D vector\n",
    "noise = np.random.normal(0, 1, size=3)\n",
    "\n",
    "# Normalize and scale to magnitude 0.1\n",
    "noise = noise / np.linalg.norm(noise) * 0.5\n",
    "# Add to translation\n",
    "pose_noisy[:3, 3] += noise\n",
    "\n",
    "print(\"Original translation:\", poses[1][:3, 3])\n",
    "print(\"Noise vector (|noise|=%.3f):\" % np.linalg.norm(noise), noise)\n",
    "print(\"Noisy translation:   \", pose_noisy[:3, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8e4e3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_0,pcd_1.transform(poses[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "652dfbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_0,pcdcam0])\n",
    "# o3d.visualization.draw_geometries([pcd_1,pcdcam1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a2e7d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "pcd_1_noise = copy.deepcopy(pcd_1)\n",
    "pcd_1_noise.transform(pose_noisy)\n",
    "o3d.visualization.draw_geometries([pcd_0,pcd_1_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7c548766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICP fitness: 0.6654592595416937\n",
      "ICP inlier RMSE: 0.23076772991673317\n",
      "Estimated transformation:\n",
      " [[ 9.99886551e-01  2.96943821e-03  1.47671009e-02 -5.67289932e-01]\n",
      " [-2.98679718e-03  9.99994874e-01  1.15358330e-03 -2.43166811e-01]\n",
      " [-1.47636000e-02 -1.19755871e-03  9.99890295e-01  1.72311722e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# Make copies to avoid modifying originals\n",
    "source = pcd_1_noise  # source cloud (moved by initial pose)\n",
    "target = pcd_0        # target cloud\n",
    "\n",
    "# # Downsample (optional, helps ICP)\n",
    "source_down = source.voxel_down_sample(voxel_size=0.1)\n",
    "target_down = target.voxel_down_sample(voxel_size=0.1)\n",
    "\n",
    "# No normals needed for point-to-point ICP, but wonâ€™t hurt if already estimated\n",
    "\n",
    "# Run ICP (point-to-point)\n",
    "threshold = 0.75  # distance threshold\n",
    "trans_init = np.eye(4)  # initial guess\n",
    "\n",
    "icp_result = o3d.pipelines.registration.registration_icp(\n",
    "    source_down, target_down, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    ")\n",
    "\n",
    "print(\"ICP fitness:\", icp_result.fitness)\n",
    "print(\"ICP inlier RMSE:\", icp_result.inlier_rmse)\n",
    "print(\"Estimated transformation:\\n\", icp_result.transformation @ poses[1])\n",
    "\n",
    "# Apply ICP transformation to the original high-res source\n",
    "source.transform(icp_result.transformation)\n",
    "\n",
    "# Visualize aligned point clouds\n",
    "o3d.visualization.draw_geometries([target, source])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "97180192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated transformation:\n",
      " [[ 9.99999492e-01 -4.59937736e-04  8.97313147e-04 -2.75052322e-02]\n",
      " [ 4.58316128e-04  9.99998264e-01  1.80626775e-03  1.77621466e-02]\n",
      " [-8.98142638e-04 -1.80585555e-03  9.99997966e-01  1.18447069e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[[ 9.99997712e-01  1.27636482e-03  1.71671717e-03 -5.41079112e-04]\n",
      " [-1.27807702e-03  9.99998687e-01  9.96494015e-04  6.73737006e-03]\n",
      " [-1.71544330e-03 -9.98685796e-04  9.99998030e-01  1.18557022e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated transformation:\\n\", icp_result.transformation @ pose_noisy)\n",
    "\n",
    "print(poses[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526a3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reloc3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
